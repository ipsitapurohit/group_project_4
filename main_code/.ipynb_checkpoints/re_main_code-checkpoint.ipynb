{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888e5d2d",
   "metadata": {},
   "source": [
    "# Real Estate Stock Price Prediction - Data cleaning and preparation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "810abf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries for the project\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f94b8b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path to database: C:\\Users\\ipsit\\Downloads\\florida_data.db\n"
     ]
    }
   ],
   "source": [
    "# db connection\n",
    "db_file = os.path.abspath('florida_data.db')\n",
    "engine = create_engine(f'sqlite:///{db_file}')\n",
    "\n",
    "# Print the absolute path to verify\n",
    "print(f\"Absolute path to database: {db_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3aa97539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing the connection with sqlite\n",
    "query = '''SELECT * FROM florida_data_cleaned'''\n",
    "re_df1 = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d85bf089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>city</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>state</th>\n",
       "      <th>house_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Malabar</td>\n",
       "      <td>32950.0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>349000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Palm Bay</td>\n",
       "      <td>32905.0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Out of State</td>\n",
       "      <td>None</td>\n",
       "      <td>Florida</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Out of State</td>\n",
       "      <td>None</td>\n",
       "      <td>Florida</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price   bed  bath          city zip_code    state house_size\n",
       "0  1500000.0  None  None       Malabar  32950.0  Florida       None\n",
       "1   436000.0  None  None          None  99999.0  Florida       None\n",
       "2   349000.0  None  None      Palm Bay  32905.0  Florida       None\n",
       "3   100000.0  None  None  Out of State     None  Florida       None\n",
       "4    52000.0  None  None  Out of State     None  Florida       None"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few records\n",
    "re_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8068a5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249432, 7)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display number of rows and columns\n",
    "re_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "22cc817c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['brokered_by', 'status', 'street', 'prev_sold_date', 'acre_lot'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Drop columns that are not needed for data analysis\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m re_df2 \u001b[38;5;241m=\u001b[39m re_df1\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrokered_by\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreet\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_sold_date\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macre_lot\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['brokered_by', 'status', 'street', 'prev_sold_date', 'acre_lot'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop columns that are not needed for data analysis\n",
    "re_df2 = re_df1.drop(['brokered_by','status','street','state','prev_sold_date','acre_lot'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489cad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few records of updated dataframe\n",
    "re_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222f286",
   "metadata": {},
   "source": [
    "# Data cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find count of rows with null values for each of the category\n",
    "re_df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0848952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows with null values\n",
    "re_df_clean = re_df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf111d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any rows have null values now\n",
    "re_df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96083c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display few of the rows of the updated dataframe\n",
    "re_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows and cloumns of the updated dataframe\n",
    "re_df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f24310",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b86f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df_clean['bed'] = re_df_clean['bed'].astype(int)\n",
    "re_df_clean['bath'] = re_df_clean['bath'].astype(int)\n",
    "re_df_clean['price'] = re_df_clean['price'].astype(int)\n",
    "re_df_clean['house_size'] = re_df_clean['house_size'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bbde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of rows with number of bedrooms > 10\n",
    "re_df_clean[re_df_clean.bed>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with bed size > 10 removed\n",
    "re_df_cleaned = re_df_clean[re_df_clean['bed'] <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e411a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some of the rows of the cleaned dataset\n",
    "re_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c1ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows and columns of the updated dataframe\n",
    "re_df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any rows with number of beds > 10\n",
    "re_df_cleaned[re_df_cleaned.bed>10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3234af",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataframe into new dataframe to create an additional column i.e. price_per_sqft\n",
    "re_df_cleaned2 = re_df_cleaned.copy()\n",
    "re_df_cleaned2['price_per_sqft'] = (re_df_cleaned['price'] / re_df_cleaned['house_size']).round(2)\n",
    "re_df_cleaned2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique count of cities\n",
    "len(re_df_cleaned2.city.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up city column values by removing leading and trailing spaces\n",
    "re_df_cleaned2.city = re_df_cleaned2.city.apply(lambda x: x.strip())\n",
    "\n",
    "# Find and display  the count of rows per city\n",
    "city_stats = re_df_cleaned2.groupby('city')['city'].agg('count').sort_values(ascending = False)\n",
    "city_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out count of cities with less than 10 data points\n",
    "len(city_stats[city_stats<=10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cities with less than 10 data points\n",
    "city_stats_less_than_10 = city_stats[city_stats<=10]\n",
    "city_stats_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14bb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all the cities with less than 10 data points with \"other\"\n",
    "re_df_cleaned2.city = re_df_cleaned2.city.apply(lambda x: 'other' if x in city_stats_less_than_10 else x)\n",
    "len(re_df_cleaned2.city.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df_cleaned2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b6439",
   "metadata": {},
   "source": [
    "# Outlier detection and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfebabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the data points where total square feet of the house divided by number of bedrooms is less than 300\n",
    "re_df_cleaned2[(re_df_cleaned2.house_size/re_df_cleaned2.bed)<300].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df_cleaned2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a621e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove above outliers\n",
    "re_df_cleaned3 = re_df_cleaned2[~((re_df_cleaned2.house_size/re_df_cleaned2.bed)<300)]\n",
    "re_df_cleaned3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extremely low and extremely high price per sqft columns\n",
    "re_df_cleaned3.price_per_sqft.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954229f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to remove outliers  \n",
    "\n",
    "def remove_ppsqft_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('city'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "\n",
    "re_df_cleaned4 = remove_ppsqft_outliers(re_df_cleaned3)\n",
    "re_df_cleaned4.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram with price per square feet and count of data points\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.hist(re_df_cleaned4.price_per_sqft)\n",
    "plt.xlabel(\"Price per square feet\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram with number of bathrooms and count of data points\n",
    "plt.hist(re_df_cleaned4.bath)\n",
    "plt.xlabel(\"Number of bathrooms\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d26843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out data points where number of bathrooms is greater than bedrooms + 2\n",
    "re_df_cleaned4[re_df_cleaned4.bath>re_df_cleaned4.bed+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data points where number of bathrooms is greater than bedrooms + 2\n",
    "re_df_cleaned5 = re_df_cleaned4[~(re_df_cleaned4.bath>re_df_cleaned4.bed+2)]\n",
    "re_df_cleaned5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop price_per_sqft,zip_code columns\n",
    "re_df_cleaned6 = re_df_cleaned5.drop(columns=['price_per_sqft','zip_code'])\n",
    "re_df_cleaned6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744c02e",
   "metadata": {},
   "source": [
    "# Build Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78119282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'city' column is of string type\n",
    "re_df_cleaned6['city'] = re_df_cleaned6['city'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e3832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dummy variables for the 'city' column\n",
    "city_dummies = pd.get_dummies(re_df_cleaned6['city'])\n",
    "\n",
    "# Ensure the dummy variables are 0 and 1\n",
    "city_dummies = city_dummies.astype(int)\n",
    "\n",
    "# Print dummy variables\n",
    "city_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458cc45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'other' column\n",
    "re_df_cleaned7 = pd.concat([re_df_cleaned6,city_dummies.drop('other',axis='columns')],axis='columns')\n",
    "re_df_cleaned7.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping city column\n",
    "re_df_cleaned8 = re_df_cleaned7.drop('city',axis='columns')\n",
    "re_df_cleaned8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e40365",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df_cleaned8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x and y axis for the dataset\n",
    "x = re_df_cleaned8.drop('price',axis='columns')\n",
    "x.shape\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3529029",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = re_df_cleaned8.price\n",
    "y.shape\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9688a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function from scikit-learn's model_selection module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets with 80% data used for training and 20% used for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a248697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearRegression class from scikit-learn's linear_model module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create an instance of the LinearRegression class, which represents the linear regression model\n",
    "lr_clf = LinearRegression()\n",
    "\n",
    "# Train the linear regression model using the training data\n",
    "lr_clf.fit(x_train,y_train)\n",
    "\n",
    "# Evaluate the model's performance using the testing data and return the coefficient of determination (R^2 score)\n",
    "lr_clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4617cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(),x,y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca75d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515315cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_price(bed, bath, sqft, city):    \n",
    "    # Check if city exists in the columns\n",
    "    if city in x.columns:\n",
    "        loc_index = np.where(x.columns == city)[0][0]\n",
    "    else:\n",
    "        loc_index = -1  # Set to -1 if city is not found\n",
    "    \n",
    "    # Create a zero array of the same length as the number of columns in x\n",
    "    x1 = np.zeros(len(x.columns))\n",
    "    \n",
    "    # Assign the input features to the appropriate positions in the array\n",
    "    x1[0] = bed\n",
    "    x1[1] = bath\n",
    "    x1[2] = sqft\n",
    "    \n",
    "    # If the city is found, set its position to 1\n",
    "    if loc_index >= 0:\n",
    "        x1[loc_index] = 1\n",
    "    \n",
    "    # Reshape x1 to a 2D array (1 sample, many features)\n",
    "    x1 = x1.reshape(1, -1)\n",
    "    \n",
    "    # Return the predicted price using the trained model\n",
    "    return lr_clf.predict(x1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the model is working\n",
    "predict_price(3, 2, 2000, 'Wimauma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830fd153",
   "metadata": {},
   "source": [
    "# Export the tested model to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae07f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('florida_home_prices_model.pickle','wb') as f:\n",
    "    pickle.dump(lr_clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b4daa",
   "metadata": {},
   "source": [
    "# Export location and column information to a file that will be useful later on in our prediction application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eaa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "columns = {\n",
    "    'data_columns' : [col.lower() for col in x.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48254f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e325265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
